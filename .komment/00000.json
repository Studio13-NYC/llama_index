[
  {
    "name": "context_retriever_agent.py",
    "path": "llama_index/agent/context_retriever_agent.py",
    "content": {
      "structured": {
        "description": "A context retriever agent based on OpenAI's LLM (Large Language Model) and llama-index library. The agent retrieves relevant information from a retriever before calling the LLM for further processing, allowing it to augment user messages with context. It also provides support for chat history, callback management, and tool choice selection.",
        "items": [
          {
            "id": "2de5fc94-c830-1696-7f44-6ad1d9a71818",
            "ancestors": [],
            "description": "Is an OpenAI agent that retrieves context nodes from a retriever and formats them into a query string to interact with a large language model (LLM). It provides both synchronous (`chat`) and asynchronous (`achat`) methods for chatting.",
            "attributes": [
              {
                "name": "_tools",
                "type_name": "List[BaseTool]",
                "description": "Initialized in the `__init__` method. It holds a list of BaseTool objects, which are used by the agent to perform various tasks."
              },
              {
                "name": "_qa_prompt",
                "type_name": "PromptTemplate",
                "description": "Used to format a query string. It takes the context string, obtained by joining retrieved texts from the retriever, and combines it with the original message to form a formatted query string for OpenAI API calls."
              },
              {
                "name": "_retriever",
                "type_name": "BaseRetriever",
                "description": "Used for retrieving nodes from a knowledge graph based on a given input message."
              },
              {
                "name": "_context_separator",
                "type_name": "str",
                "description": "Used to separate context strings retrieved from the retriever."
              }
            ],
            "name": "ContextRetrieverOpenAIAgent",
            "location": {
              "start": 36,
              "insert": 37,
              "offset": " ",
              "indent": 4,
              "comment": {
                "start": 36,
                "end": 56
              }
            },
            "item_type": "class",
            "length": 123,
            "docLength": 20
          },
          {
            "id": "8ce24f00-4101-bdb6-d847-e976770fede0",
            "ancestors": [
              "2de5fc94-c830-1696-7f44-6ad1d9a71818"
            ],
            "description": "Initializes an instance with specified parameters: tools, retriever, prompt template, separator, OpenAI language model, memory, prefix messages, verbosity, maximum function calls, and callback manager. It sets attributes for these parameters and calls its parent's `__init__` method.",
            "params": [
              {
                "name": "tools",
                "type_name": "List[BaseTool]",
                "description": "Initialized with the value provided to it during object creation."
              },
              {
                "name": "retriever",
                "type_name": "BaseRetriever",
                "description": "Assigned to an instance variable `_retriever`. This suggests that retriever is responsible for retrieving relevant information from a source, possibly a database or another data structure."
              },
              {
                "name": "qa_prompt",
                "type_name": "PromptTemplate",
                "description": "Assigned to an instance variable with the same name. This suggests that `qa_prompt` represents a template for constructing questions or prompts used in question-answering processes."
              },
              {
                "name": "context_separator",
                "type_name": "str",
                "description": "Used to separate multiple contexts in the input. It appears to play a crucial role in handling context-switching operations within the class's functionality."
              },
              {
                "name": "llm",
                "type_name": "OpenAI",
                "description": "Used to represent an instance of an open AI language model, which will be utilized by the class for natural language processing tasks."
              },
              {
                "name": "memory",
                "type_name": "BaseMemory",
                "description": "Used to initialize an instance of this class. It represents the memory component responsible for storing and managing context information during conversations."
              },
              {
                "name": "prefix_messages",
                "type_name": "List[ChatMessage]",
                "description": "Initialized to an empty list by default. It represents a collection of messages that serve as prefixes for conversation flows."
              },
              {
                "name": "verbose",
                "type_name": "bool",
                "description": "False by default. It controls the verbosity level of the object, enabling or disabling detailed logging information during its operation."
              },
              {
                "name": "max_function_calls",
                "type_name": "int",
                "description": "0 by default. It limits the number of recursive function calls allowed before raising an exception, ensuring against infinite recursion and potential stack overflow."
              },
              {
                "name": "callback_manager",
                "type_name": "Optional[CallbackManager]",
                "description": "Optional by default. It allows for an external CallbackManager instance to be passed, which can manage callback functions used by other parts of the class."
              }
            ],
            "returns": null,
            "usage": {
              "language": "python",
              "code": "tools = [Tool1(), Tool2()]\nretriever = BaseRetriever()\nqa_prompt = PromptTemplate()\ncontext_separator = \"\\n\"\nllm = OpenAI()\nmemory = BaseMemory()\n\nagent = ContextRetrieverOpenAIAgent(\n    tools=tools,\n    retriever=retriever,\n    qa_prompt=qa_prompt,\n    context_separator=context_separator,\n    llm=llm,\n    memory=memory,\n)",
              "description": ""
            },
            "name": "__init__",
            "location": {
              "start": 58,
              "insert": 71,
              "offset": " ",
              "indent": 8,
              "comment": null
            },
            "item_type": "constructor",
            "length": 25,
            "docLength": null
          },
          {
            "id": "b72c8ae4-1eac-12a0-204d-ac4201b9871a",
            "ancestors": [
              "2de5fc94-c830-1696-7f44-6ad1d9a71818"
            ],
            "description": "Initializes an instance with given tools, retriever, and options for OpenAI interaction, including LLMAgent model, memory buffer, and callback manager. It sets default values for optional parameters and validates input.",
            "params": [
              {
                "name": "tools",
                "type_name": "List[BaseTool]",
                "description": "Required. It represents a list of base tools used for context retrieval."
              },
              {
                "name": "retriever",
                "type_name": "BaseRetriever",
                "description": "Required for constructing an instance of `ContextRetrieverOpenAIAgent`."
              },
              {
                "name": "qa_prompt",
                "type_name": "Optional[PromptTemplate]",
                "description": "Set to None by default. It is used as a prompt for asking questions during conversations, with the DEFAULT_QA_PROMPT as its fallback value if not provided."
              },
              {
                "name": "context_separator",
                "type_name": "str",
                "description": "Used to separate context parts when constructing the prompt for the retrieval model. It defaults to \"\\n\"."
              },
              {
                "name": "llm",
                "type_name": "Optional[LLM]",
                "description": "Used to set the language model, which defaults to OpenAI if not provided."
              },
              {
                "name": "chat_history",
                "type_name": "Optional[List[ChatMessage]]",
                "description": "Optional, meaning it defaults to an empty list if not provided. It stores previous messages exchanged between the user and the chatbot."
              },
              {
                "name": "memory",
                "type_name": "Optional[BaseMemory]",
                "description": "Optional by default. If provided, it will be used as the memory instance; otherwise, a default memory instance is created from chat history and LLM using the `memory_cls.from_defaults` method."
              },
              {
                "name": "memory_cls",
                "type_name": "Type[BaseMemory]",
                "description": "Set to `ChatMemoryBuffer` by default. It allows users to specify an alternate memory class if needed, overriding the default behavior."
              },
              {
                "name": "verbose",
                "type_name": "bool",
                "description": "False by default. It controls the level of verbosity when the class is instantiated, which could potentially affect logging or other output produced by the class."
              },
              {
                "name": "max_function_calls",
                "type_name": "int",
                "description": "Used to set the maximum number of recursive calls allowed for the LLM model."
              },
              {
                "name": "callback_manager",
                "type_name": "Optional[CallbackManager]",
                "description": "Used to configure callbacks for the LLM. It allows the developer to manage callback functions that are triggered during the execution of certain events in the OpenAI model."
              },
              {
                "name": "system_prompt",
                "type_name": "Optional[str]",
                "description": "Used to specify a system prompt for the context retriever. If provided, this prompt will be added as the first message in the chat history."
              },
              {
                "name": "prefix_messages",
                "type_name": "Optional[List[ChatMessage]]",
                "description": "Used to specify prefix messages for the context retriever. It can be used to provide additional context or system information."
              }
            ],
            "returns": {
              "type_name": "\"ContextRetrieverOpenAIAgent\"",
              "description": "An instance of a class. This object represents an OpenAI agent that uses a retriever and tools to interact with users, based on the input parameters provided."
            },
            "usage": {
              "language": "python",
              "code": "llm = OpenAI(model=DEFAULT_MODEL_NAME)\nchat_history = []\nmemory = ChatMemoryBuffer.from_defaults(chat_history, llm)\ntools = [BaseTool1(), BaseTool2()]\nretriever = BaseRetriever()\nqa_prompt = PromptTemplate(\"Prompt for Q&A\")\nprefix_messages = []\n\nContextRetrieverOpenAIAgent.from_tools_and_retriever(\n    tools,\n    retriever,\n    qa_prompt,\n    llm=llm,\n    memory=memory,\n    prefix_messages=prefix_messages\n)",
              "description": ""
            },
            "name": "from_tools_and_retriever",
            "location": {
              "start": 84,
              "insert": 101,
              "offset": " ",
              "indent": 8,
              "comment": {
                "start": 100,
                "end": 113
              }
            },
            "item_type": "classmethod",
            "length": 52,
            "docLength": 13
          },
          {
            "id": "d718831d-10e5-eeab-2e4a-4bf5efd4054c",
            "ancestors": [
              "2de5fc94-c830-1696-7f44-6ad1d9a71818"
            ],
            "description": "Retrieves relevant nodes and their scores from the input message, extracts node contents, concatenates them into a context string, and then formats an OpenAI query prompt using this context string and the original message.",
            "name": "_build_formatted_message",
            "location": {
              "start": 154,
              "insert": 156,
              "offset": " ",
              "indent": 8,
              "comment": null
            },
            "item_type": "method",
            "length": 9,
            "docLength": null
          },
          {
            "id": "5f9d8983-f712-088d-bb4d-af4ec4e11113",
            "ancestors": [
              "2de5fc94-c830-1696-7f44-6ad1d9a71818"
            ],
            "description": "Processes user input, formats it, and sends it to the superclass for further processing. It also handles chat history and tool choice configuration.",
            "params": [
              {
                "name": "message",
                "type_name": "str",
                "description": "Required. It represents the message to be sent through the chat interface and will be used as an input for generating the response from the agent."
              },
              {
                "name": "chat_history",
                "type_name": "Optional[List[ChatMessage]]",
                "description": "Optional by default with a value of None, allowing for the chat history to be passed as an argument or not at all."
              },
              {
                "name": "tool_choice",
                "type_name": "Union[str, dict]",
                "description": "Default set to \"auto\". It accepts either a string or a dictionary as its value and controls the tool used for the chat session."
              }
            ],
            "returns": {
              "type_name": "AgentChatResponse",
              "description": "Likely a response generated by an AI agent or a conversational model after processing the input message and any relevant context from the chat history."
            },
            "usage": {
              "language": "python",
              "code": "agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(\n    tools=[BaseTool()],\n    retriever=BaseRetriever(),\n    qa_prompt=None,\n)\nresponse = agent.chat(\"What's your name?\", tool_choice=\"auto\")",
              "description": ""
            },
            "name": "chat",
            "location": {
              "start": 166,
              "insert": 172,
              "offset": " ",
              "indent": 8,
              "comment": {
                "start": 171,
                "end": 172
              }
            },
            "item_type": "method",
            "length": 13,
            "docLength": 1
          },
          {
            "id": "2635c8aa-7fdc-06ac-8342-63fccadce870",
            "ancestors": [
              "2de5fc94-c830-1696-7f44-6ad1d9a71818"
            ],
            "description": "Formats and prints a message if verbose mode is on, then calls its superclass's `achat` method with formatted message, chat history, and tool choice.",
            "params": [
              {
                "name": "message",
                "type_name": "str",
                "description": "Required by default. It represents a message that is passed to the chatbot for processing."
              },
              {
                "name": "chat_history",
                "type_name": "Optional[List[ChatMessage]]",
                "description": "Optional. It allows for passing chat history, if available, to assist in processing the current message."
              },
              {
                "name": "tool_choice",
                "type_name": "Union[str, dict]",
                "description": "Optional with a default value of \"auto\". This means it can be either a string or a dictionary, and if not provided, it defaults to \"auto\"."
              }
            ],
            "returns": {
              "type_name": "AgentChatResponse",
              "description": "Awaited from a superclass's method with the same name. The returned response likely contains information about the chat interaction, possibly including the generated response to the input message."
            },
            "usage": {
              "language": "python",
              "code": "agent = ContextRetrieverOpenAIAgent.from_tools_and_retriever(tools=tools, retriever=retriever)\nresponse = await agent.achat(\"Hello, what can I help you with?\", chat_history=[...])\n",
              "description": "\nNote that this example assumes that the tools and retriever have been properly initialized before calling the achat method."
            },
            "name": "achat",
            "location": {
              "start": 181,
              "insert": 187,
              "offset": " ",
              "indent": 8,
              "comment": {
                "start": 186,
                "end": 187
              }
            },
            "item_type": "method",
            "length": 13,
            "docLength": 1
          }
        ]
      }
    }
  }
]